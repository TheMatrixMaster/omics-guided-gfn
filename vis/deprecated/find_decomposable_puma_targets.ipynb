{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/s/stephen.lu/miniconda3/envs/gfn/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import hydra\n",
    "import torch\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from pytorch_lightning import (\n",
    "    LightningDataModule,\n",
    "    seed_everything,\n",
    ")\n",
    "\n",
    "import umap\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Draw\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import *\n",
    "from multimodal_contrastive.utils import utils\n",
    "from gflownet.envs.frag_mol_env import FragMolBuildingEnvContext, _recursive_decompose\n",
    "\n",
    "# register custom resolvers if not already registered\n",
    "OmegaConf.register_new_resolver(\"sum\", lambda input_list: np.sum(input_list), replace=True)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shuffled_scaffold'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load config for CLIP model\n",
    "config_name = \"jump_sm_gmc\"\n",
    "configs_path = \"../../configs\"\n",
    "\n",
    "with hydra.initialize(version_base=None, config_path=configs_path):\n",
    "    cfg = hydra.compose(config_name=config_name)\n",
    "\n",
    "cfg.datamodule.split_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading some Tensorflow models, missing a dependency. No module named 'tensorflow'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on samples from shuffled_scaffold.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08:48:19] Unusual charge on atom 3 number of radical electrons set to zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90862 samples.\n",
      "Validate on 11358 samples.\n",
      "Test on 11358 samples.\n"
     ]
    }
   ],
   "source": [
    "# Set seed for random number generators in pytorch, numpy and python.random\n",
    "# and especially for generating the same data splits for the test set\n",
    "if cfg.get(\"seed\"):\n",
    "    seed_everything(cfg.seed, workers=True)\n",
    "\n",
    "# Load test data split\n",
    "datamodule: LightningDataModule = hydra.utils.instantiate(cfg.datamodule)\n",
    "datamodule.setup(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from checkpoint\n",
    "ckpt_path = \"/home/mila/s/stephen.lu/gfn_gene/res/mmc/models/morph_struct_90_step_val_loss.ckpt\"\n",
    "model = utils.instantiate_model(cfg)\n",
    "model = model.load_from_checkpoint(ckpt_path, map_location=device)\n",
    "model = model.eval()\n",
    "\n",
    "# Get latent representations for full dataset\n",
    "representations = model.compute_representation_dataloader(\n",
    "    make_eval_data_loader(datamodule.dataset),\n",
    "    device=device,\n",
    "    return_mol=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a frag building environment, so that we can use the mol_to_graph() function to attempt to \n",
    "# factorize the molecules in the puma dataset into their constituent fragments\n",
    "env = FragMolBuildingEnvContext()\n",
    "\n",
    "def mol_to_graph(environ, mol):\n",
    "    \"\"\"Convert an RDMol to a Graph\"\"\"\n",
    "    assert type(mol) is Chem.Mol\n",
    "    all_matches = {}\n",
    "    for fragidx, frag in environ.sorted_frags:\n",
    "        all_matches[fragidx] = mol.GetSubstructMatches(frag, uniquify=False)\n",
    "    return _recursive_decompose(environ, mol, all_matches, {}, [], [], 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def go(dataset):\n",
    "    decomposed_samples = {}\n",
    "    for idx, sample in enumerate(tqdm(dataset)):\n",
    "        smiles = sample[\"inputs\"][\"struct\"].mols\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        try:\n",
    "            g = mol_to_graph(env, mol)\n",
    "            if g != None:\n",
    "                print(idx, f\"Factorized with {g.number_of_nodes()} nodes.\")\n",
    "                decomposed_samples[idx] = (sample, g)\n",
    "        except ValueError as e:\n",
    "            continue\n",
    "    return decomposed_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/113578 [00:00<3:20:05,  9.46it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Factorized with 6 nodes.\n",
      "4 Factorized with 3 nodes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 36/113578 [00:07<3:01:10, 10.44it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 Factorized with 8 nodes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 56/113578 [00:10<3:46:53,  8.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 Factorized with 4 nodes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 93/113578 [00:19<8:47:07,  3.59it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91 Factorized with 6 nodes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 121/113578 [00:25<3:38:02,  8.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119 Factorized with 6 nodes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 131/113578 [00:26<3:06:04, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129 Factorized with 3 nodes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 142/113578 [00:28<5:16:04,  5.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140 Factorized with 4 nodes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 151/113578 [00:29<6:12:02,  5.08it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m decomposed_samples \u001b[38;5;241m=\u001b[39m \u001b[43mgo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# save the samples that were successfully factorized\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecomposed_samples_jump.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m, in \u001b[0;36mgo\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m      5\u001b[0m mol \u001b[38;5;241m=\u001b[39m Chem\u001b[38;5;241m.\u001b[39mMolFromSmiles(smiles)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 7\u001b[0m     g \u001b[38;5;241m=\u001b[39m \u001b[43mmol_to_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m g \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28mprint\u001b[39m(idx, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFactorized with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mg\u001b[38;5;241m.\u001b[39mnumber_of_nodes()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m nodes.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m, in \u001b[0;36mmol_to_graph\u001b[0;34m(environ, mol)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fragidx, frag \u001b[38;5;129;01min\u001b[39;00m environ\u001b[38;5;241m.\u001b[39msorted_frags:\n\u001b[1;32m     10\u001b[0m     all_matches[fragidx] \u001b[38;5;241m=\u001b[39m mol\u001b[38;5;241m.\u001b[39mGetSubstructMatches(frag, uniquify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_recursive_decompose\u001b[49m\u001b[43m(\u001b[49m\u001b[43menviron\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_matches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/gfn_gene/gflownet/src/gflownet/envs/frag_mol_env.py:550\u001b[0m, in \u001b[0;36m_recursive_decompose\u001b[0;34m(ctx, m, all_matches, a2f, frags, bonds, max_depth, numiters)\u001b[0m\n\u001b[1;32m    546\u001b[0m                 possible_bonds\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    547\u001b[0m                     (other_frag_idx, new_frag_idx, other_frag_stemidx, this_frag_stemidx, i, j)\n\u001b[1;32m    548\u001b[0m                 )\n\u001b[1;32m    549\u001b[0m new_bonds \u001b[38;5;241m=\u001b[39m bonds \u001b[38;5;241m+\u001b[39m possible_bonds\n\u001b[0;32m--> 550\u001b[0m dec \u001b[38;5;241m=\u001b[39m \u001b[43m_recursive_decompose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_matches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_a2f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_frags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_bonds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumiters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dec:\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dec\n",
      "File \u001b[0;32m~/gfn_gene/gflownet/src/gflownet/envs/frag_mol_env.py:550\u001b[0m, in \u001b[0;36m_recursive_decompose\u001b[0;34m(ctx, m, all_matches, a2f, frags, bonds, max_depth, numiters)\u001b[0m\n\u001b[1;32m    546\u001b[0m                 possible_bonds\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    547\u001b[0m                     (other_frag_idx, new_frag_idx, other_frag_stemidx, this_frag_stemidx, i, j)\n\u001b[1;32m    548\u001b[0m                 )\n\u001b[1;32m    549\u001b[0m new_bonds \u001b[38;5;241m=\u001b[39m bonds \u001b[38;5;241m+\u001b[39m possible_bonds\n\u001b[0;32m--> 550\u001b[0m dec \u001b[38;5;241m=\u001b[39m \u001b[43m_recursive_decompose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_matches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_a2f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_frags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_bonds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumiters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dec:\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dec\n",
      "    \u001b[0;31m[... skipping similar frames: _recursive_decompose at line 550 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/gfn_gene/gflownet/src/gflownet/envs/frag_mol_env.py:550\u001b[0m, in \u001b[0;36m_recursive_decompose\u001b[0;34m(ctx, m, all_matches, a2f, frags, bonds, max_depth, numiters)\u001b[0m\n\u001b[1;32m    546\u001b[0m                 possible_bonds\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    547\u001b[0m                     (other_frag_idx, new_frag_idx, other_frag_stemidx, this_frag_stemidx, i, j)\n\u001b[1;32m    548\u001b[0m                 )\n\u001b[1;32m    549\u001b[0m new_bonds \u001b[38;5;241m=\u001b[39m bonds \u001b[38;5;241m+\u001b[39m possible_bonds\n\u001b[0;32m--> 550\u001b[0m dec \u001b[38;5;241m=\u001b[39m \u001b[43m_recursive_decompose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_matches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_a2f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_frags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_bonds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumiters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dec:\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dec\n",
      "File \u001b[0;32m~/gfn_gene/gflownet/src/gflownet/envs/frag_mol_env.py:520\u001b[0m, in \u001b[0;36m_recursive_decompose\u001b[0;34m(ctx, m, all_matches, a2f, frags, bonds, max_depth, numiters)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_valid_match:\n\u001b[1;32m    519\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 520\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m this_frag_stemidx, i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m([match[s] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39mfrags_stems[fragidx]]):\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m m\u001b[38;5;241m.\u001b[39mGetAtomWithIdx(i)\u001b[38;5;241m.\u001b[39mGetNeighbors():\n\u001b[1;32m    522\u001b[0m         j \u001b[38;5;241m=\u001b[39m j\u001b[38;5;241m.\u001b[39mGetIdx()\n",
      "File \u001b[0;32m~/gfn_gene/gflownet/src/gflownet/envs/frag_mol_env.py:520\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_valid_match:\n\u001b[1;32m    519\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 520\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m this_frag_stemidx, i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m([match[s] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39mfrags_stems[fragidx]]):\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m m\u001b[38;5;241m.\u001b[39mGetAtomWithIdx(i)\u001b[38;5;241m.\u001b[39mGetNeighbors():\n\u001b[1;32m    522\u001b[0m         j \u001b[38;5;241m=\u001b[39m j\u001b[38;5;241m.\u001b[39mGetIdx()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "decomposed_samples = go(datamodule.dataset)\n",
    "# save the samples that were successfully factorized\n",
    "with open(f\"decomposed_samples_jump.pkl\", \"wb\") as f:\n",
    "    pickle.dump(decomposed_samples, f)\n",
    "\n",
    "# or load from file\n",
    "# with open(\"/home/mila/s/stephen.lu/gfn_gene/res/mmc/data/decomposed_samples_puma.pkl\", \"rb\") as f:\n",
    "#     decomposed_samples = pickle.load(f)\n",
    "\n",
    "# # convert to a dictionary indexed by the sample index\n",
    "# decomposed_samples = {idx: (sample, graph) for idx, sample, graph in decomposed_samples}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns=[\"smiles\"])\n",
    "for idx, (sample, graph) in decomposed_samples.items():\n",
    "    df.loc[idx] = {\"smiles\": sample[\"inputs\"][\"struct\"].mols}\n",
    "\n",
    "df.to_csv(\"decomposed_samples_puma.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the decomposed_samples that also happen to be apart of the test split\n",
    "train_idx, val_idx, test_idx = datamodule.get_split_idx()\n",
    "test_decomposed_samples = {idx: (sample, graph) for idx, (sample, graph) in decomposed_samples.items() if idx in test_idx}\n",
    "len(test_decomposed_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a the samples that were factorized from the test set\n",
    "fig, ax = plt.subplots(2, 4, figsize=(16, 8))\n",
    "some_samples = list(test_decomposed_samples.keys())[:8]\n",
    "\n",
    "for idx, sample_idx in enumerate(some_samples):\n",
    "    sample, g = test_decomposed_samples[sample_idx]\n",
    "    smiles = sample[\"inputs\"][\"struct\"].mols\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    img = Draw.MolToImage(mol)\n",
    "    n_atoms = mol.GetNumAtoms()\n",
    "    n_bonds = mol.GetNumBonds()\n",
    "    \n",
    "    ax[idx//4, idx%4].imshow(img)\n",
    "    ax[idx//4, idx%4].set_title(f\"Sample {sample_idx} \\n{g.number_of_nodes()} frags, {n_atoms} atoms, {n_bonds} bonds\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the umap of raw morph features of the entire dataset and plot the factorized sample\n",
    "# morph features on top of it in a different color\n",
    "\n",
    "factorized_idx = list(decomposed_samples.keys())\n",
    "fact_morph = np.array([x[0][\"inputs\"][\"morph\"].numpy() for x in decomposed_samples.values()])\n",
    "\n",
    "non_factorized_idx = np.random.choice(range(len(datamodule.dataset)), size=2000, replace=False)\n",
    "non_fact_morph = np.array([datamodule.dataset[i][\"inputs\"][\"morph\"].numpy() for i in non_factorized_idx])\n",
    "\n",
    "n_neighbors = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "fig, ax = plt.subplots(2, 5, figsize=(20, 10))\n",
    "\n",
    "for idx, n in enumerate(n_neighbors):\n",
    "    print(idx)\n",
    "    reducer = umap.UMAP(n_neighbors=n, random_state=42, verbose=True)\n",
    "    embedding = reducer.fit_transform(non_fact_morph)\n",
    "    fact_embedding = reducer.transform(fact_morph)\n",
    "\n",
    "    ax[idx//5, idx%5].scatter(embedding[:, 0], embedding[:, 1], s=1, c=\"blue\", alpha=0.5, label=\"non-factorized\")\n",
    "    ax[idx//5, idx%5].scatter(fact_embedding[:, 0], fact_embedding[:, 1], s=1, c=\"red\", alpha=0.5, label=\"factorized\")\n",
    "    ax[idx//5, idx%5].set_title(f\"n_neighbors={n}\")\n",
    "    ax[idx//5, idx%5].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "\n",
    "non_fact_morph_pca = pca.fit_transform(non_fact_morph)\n",
    "fact_morph_pca = pca.transform(fact_morph)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "ax.scatter(non_fact_morph_pca[:, 0], non_fact_morph_pca[:, 1], c=\"blue\", label=\"Non-factorized\")\n",
    "ax.scatter(fact_morph_pca[:, 0], fact_morph_pca[:, 1], c=\"red\", label=\"Factorized\")\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pca morph representations with k=30 components for all samples\n",
    "pca = PCA(n_components=30)\n",
    "morph = np.array([sample[\"inputs\"][\"morph\"].numpy() for sample in tqdm(datamodule.dataset)])\n",
    "morph_pca = pca.fit_transform(morph)\n",
    "print(morph_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct_latents = {\n",
    "    \"train\": representations['struct'][train_idx],\n",
    "    \"val\": representations['struct'][val_idx],\n",
    "    \"test\": representations['struct'][test_idx]\n",
    "}\n",
    "\n",
    "morph_pca_lib = {\n",
    "    \"train\": morph_pca[train_idx],\n",
    "    \"val\": morph_pca[val_idx],\n",
    "    \"test\": morph_pca[test_idx]\n",
    "}\n",
    "\n",
    "# target_indices = list(decomposed_samples.keys())\n",
    "# target_indices = np.random.choice(target_indices, size=5, replace=False)\n",
    "target_indices = [3165, 764, 14362, 4646, 15487]\n",
    "n_targets = len(target_indices)\n",
    "\n",
    "fig, ax = plt.subplots(n_targets, 4, figsize=(20, 5*n_targets))\n",
    "\n",
    "for i in range(n_targets):\n",
    "    # get a random target molecule and its latent representations\n",
    "    target_idx = target_indices[i]\n",
    "    sample, graph = decomposed_samples[target_idx][0], decomposed_samples[target_idx][1]\n",
    "    \n",
    "    target_joint_latent = representations['joint'][target_idx]\n",
    "    target_morph_latent = representations['morph'][target_idx]\n",
    "\n",
    "    for j, split in enumerate([\"train\", \"val\", \"test\"]):        \n",
    "        # compute cosine similarity between target and all struct latents\n",
    "        cosine_sim_joint = cosine_similarity([target_joint_latent], struct_latents[split])\n",
    "        cosine_sim_morph = cosine_similarity([target_morph_latent], struct_latents[split])\n",
    "        cosine_sim_morph_pca = cosine_similarity(morph_pca[target_idx].reshape(1, -1), morph_pca_lib[split])\n",
    "\n",
    "        # plot histogram of cosine sim\n",
    "        ax[i, 0].hist(cosine_sim_joint.flatten(), bins=50, alpha=0.5, label=split)\n",
    "        ax[i, 1].hist(cosine_sim_morph.flatten(), bins=50, alpha=0.5, label=split)\n",
    "        ax[i, 2].hist(cosine_sim_morph_pca.flatten(), bins=50, alpha=0.5, label=split)\n",
    "\n",
    "    ax[i, 0].set_title(f\"Cosine similarity to joint target {target_idx}\")\n",
    "    ax[i, 1].set_title(f\"Cosine similarity to morph target {target_idx}\")\n",
    "    ax[i, 2].set_title(f\"Cosine similarity to morph pca target {target_idx}\")\n",
    "\n",
    "    # plot the target molecule\n",
    "    smiles = sample[\"inputs\"][\"struct\"].mols\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    img = Draw.MolToImage(mol)\n",
    "    \n",
    "    num_atoms = mol.GetNumAtoms()\n",
    "    num_bonds = mol.GetNumBonds()\n",
    "\n",
    "    ax[i, 3].set_title(f\"Num atoms: {num_atoms}, Num bonds: {num_bonds}, Num frags: {graph.number_of_nodes()}\")\n",
    "    ax[i, 3].imshow(img)\n",
    "    ax[i, 3].axis(\"off\")\n",
    "\n",
    "    # with open(f\"sample_{target_idx}.pkl\", \"wb\") as f:\n",
    "    #     pickle.dump(sample, f)\n",
    "    \n",
    "    # with open(f\"sample_{target_idx}.txt\", \"wb\") as f:\n",
    "    #     f.write(smiles)\n",
    "\n",
    "ax[0, 0].legend()\n",
    "ax[0, 1].legend()\n",
    "ax[0, 2].legend()\n",
    "\n",
    "ax[n_targets-1, 0].set_xlabel(\"Cosine similarity to target joint latent\")\n",
    "ax[n_targets-1, 1].set_xlabel(\"Cosine similarity to target morph latent\")\n",
    "ax[n_targets-1, 2].set_xlabel(\"Cosine similarity to target morph pca (k=30)\")\n",
    "\n",
    "# plt.savefig(\"target_analysis_final.png\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of atoms for each factorized sample and plot histogram\n",
    "num_atoms = []\n",
    "num_bonds = []\n",
    "num_frags = []\n",
    "sample_idxs = []\n",
    "\n",
    "for idx, sample_idx in enumerate(decomposed_samples.keys()):\n",
    "    sample, graph = decomposed_samples[sample_idx]\n",
    "    smiles = sample[\"inputs\"][\"struct\"].mols\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    sample_idxs.append(sample_idx)\n",
    "    num_atoms.append(mol.GetNumAtoms())\n",
    "    num_bonds.append(mol.GetNumBonds())\n",
    "    num_frags.append(graph.number_of_nodes())\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "ax[0].hist(num_atoms, bins=50)\n",
    "ax[0].set_title(\"Num atoms\")\n",
    "\n",
    "ax[1].hist(num_bonds, bins=50)\n",
    "ax[1].set_title(\"Num bonds\")\n",
    "\n",
    "ax[2].hist(num_frags, bins=50)\n",
    "ax[2].set_title(\"Num frags\")\n",
    "\n",
    "plt.title(\"Num atoms, bonds and frags for factorized samples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the index of samples with the highest number of atoms and bonds\n",
    "sorted_by_atoms = sorted(zip(sample_idxs, num_atoms), key=lambda x: x[1], reverse=True)\n",
    "sorted_by_bonds = sorted(zip(sample_idxs, num_bonds), key=lambda x: x[1], reverse=True)\n",
    "sorted_by_frags = sorted(zip(sample_idxs, num_frags), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print([x[0] for x in sorted_by_atoms[:5]])\n",
    "print([x[0] for x in sorted_by_bonds[:5]])\n",
    "print([x[0] for x in sorted_by_frags[:5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [10852]\n",
    "\n",
    "for sample_idx in keys:\n",
    "    # assert sample_idx in test_idx\n",
    "    sample = datamodule.dataset[sample_idx]\n",
    "    struct_latent = representations['struct'][sample_idx]\n",
    "    morph_latent = representations['morph'][sample_idx]\n",
    "    joint_latent = representations['joint'][sample_idx]\n",
    "    \n",
    "    print(\n",
    "        sample_idx,\n",
    "        cosine_similarity(struct_latent.reshape(1, -1), morph_latent.reshape(1, -1)),\n",
    "        cosine_similarity(struct_latent.reshape(1, -1), joint_latent.reshape(1, -1)),\n",
    "        cosine_similarity(morph_latent.reshape(1, -1), joint_latent.reshape(1, -1))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample, graph = decomposed_samples[3165]\n",
    "sample_prime = datamodule.dataset[3165]\n",
    "\n",
    "print(sample_prime)\n",
    "print(sample)\n",
    "print(graph)\n",
    "# mol = Chem.MolFromSmiles(sample[\"inputs\"][\"struct\"].mols)\n",
    "\n",
    "# # plot molecule\n",
    "# img = Draw.MolToImage(mol)\n",
    "# plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gfn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
